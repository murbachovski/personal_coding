# ê°€ìƒí™˜ê²½ ìƒì„±
    # conda create -n hugg python=3.10
# pip install huggingface-hub
# Pip install pillow
import os
from huggingface_hub import InferenceClient
import time

# â±ï¸ ì‹œì‘ ì‹œê°„ ê¸°ë¡
start_time = time.time()

print("ì½”ë“œ ì‹œì‘")

# ğŸ”‘ Hugging Face API í† í° í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
# os.environ["HF_TOKEN"]ì— ì‚¬ì „ì— í† í°ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

# ğŸŒ InferenceClient ê°ì²´ ìƒì„± (Hugging Face Hub)
client = InferenceClient(
    provider="auto",
    api_key=os.environ["HF_TOKEN"],  # í™˜ê²½ë³€ìˆ˜ HF_TOKENì— API í‚¤ ì €ì¥ í•„ìš”
)

# ğŸ’¬ ì‚¬ìš©ìë¡œë¶€í„° ì´ë¯¸ì§€ ìƒì„±ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ ì…ë ¥ë°›ê¸°
prompt = input("ìƒì„±í•  ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”. : ")

print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘... (í”„ë¡¬í”„íŠ¸: {prompt})")

# ğŸ¤– ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
image = client.text_to_image(
    prompt,               # ìƒì„±í•  ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… í…ìŠ¤íŠ¸
    model="black-forest-labs/FLUX.1-dev",  # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
)

# ğŸ’¾ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
save_path = "result_image.png"
image.save(save_path)

print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")

# ğŸ–¼ï¸ iTerm2 í„°ë¯¸ë„ì—ì„œ ì´ë¯¸ì§€ ì¶œë ¥ (imgcat ëª…ë ¹ì–´ ì‹¤í–‰)
os.system(f"imgcat {save_path}")

# â³ ì´ ì‹¤í–‰ ì‹œê°„ ì¶œë ¥
elapsed_time = time.time() - start_time
print(f"â° ì „ì²´ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

print("âœ… ì „ì²´ ì½”ë“œê°€ ì˜ ì‹¤í–‰ë˜ì—ˆìŒ!")
